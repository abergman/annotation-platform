"""
Batch Import/Export Utilities

Advanced import and export functionality for annotations with support for
multiple formats, data validation, and progress tracking.
"""

import csv
import json
import xml.etree.ElementTree as ET
from datetime import datetime
from typing import Dict, List, Any, Optional, Union, Generator
from dataclasses import dataclass
import pandas as pd
from pathlib import Path
import logging
from io import StringIO, BytesIO

from sqlalchemy.orm import Session, sessionmaker
from sqlalchemy import func

from src.core.database import engine
from src.models.annotation import Annotation
from src.models.text import Text
from src.models.label import Label
from src.models.project import Project
from src.models.user import User

logger = logging.getLogger(__name__)


@dataclass
class ImportResult:
    """Result of an import operation."""
    success_count: int
    failure_count: int
    errors: List[Dict[str, Any]]
    imported_items: List[Any]
    validation_warnings: List[str]
    metadata: Dict[str, Any]


@dataclass
class ExportResult:
    """Result of an export operation."""
    exported_count: int
    export_file_path: str
    file_size_bytes: int
    format: str
    metadata: Dict[str, Any]


class BatchImportExport:
    """Advanced batch import/export system."""
    
    def __init__(self):
        self.session_factory = sessionmaker(bind=engine)
        self.supported_import_formats = ["csv", "json", "jsonl", "xml", "coco", "yolo"]
        self.supported_export_formats = ["csv", "json", "jsonl", "xml", "coco", "yolo", "conll"]
    
    async def import_annotations_from_file(
        self,
        file_content: bytes,
        file_format: str,
        project_id: int,
        user_id: int,
        mapping_config: Optional[Dict[str, str]] = None,
        validation_config: Optional[Dict[str, Any]] = None,
        progress_callback: Optional[callable] = None
    ) -> ImportResult:
        """
        Import annotations from various file formats.
        
        Args:
            file_content: Raw file content as bytes
            file_format: Format of the file (csv, json, etc.)
            project_id: Target project ID
            user_id: User performing the import
            mapping_config: Field mapping configuration
            validation_config: Validation rules configuration
            progress_callback: Progress callback function
            
        Returns:
            ImportResult with import statistics and errors
        """
        start_time = datetime.utcnow()
        
        try:
            # Parse file content based on format
            if file_format.lower() == "csv":
                data = self._parse_csv_content(file_content, mapping_config)
            elif file_format.lower() == "json":
                data = self._parse_json_content(file_content, mapping_config)
            elif file_format.lower() == "jsonl":
                data = self._parse_jsonl_content(file_content, mapping_config)
            elif file_format.lower() == "xml":
                data = self._parse_xml_content(file_content, mapping_config)
            elif file_format.lower() == "coco":
                data = self._parse_coco_content(file_content, project_id)
            elif file_format.lower() == "yolo":
                data = self._parse_yolo_content(file_content, project_id)
            else:
                raise ValueError(f"Unsupported import format: {file_format}")
            
            # Validate and process annotations
            session = self.session_factory()
            success_count = 0
            failure_count = 0
            errors = []
            imported_items = []
            validation_warnings = []
            
            try:
                total_items = len(data)
                
                for i, item in enumerate(data):
                    try:
                        # Validate item
                        validation_result = self._validate_import_item(\n                            item, project_id, session, validation_config\n                        )\n                        \n                        if validation_result[\"warnings\"]:\n                            validation_warnings.extend(validation_result[\"warnings\"])\n                        \n                        if not validation_result[\"valid\"]:\n                            errors.append({\n                                \"index\": i,\n                                \"item\": item,\n                                \"errors\": validation_result[\"errors\"]\n                            })\n                            failure_count += 1\n                            continue\n                        \n                        # Create annotation\n                        annotation = self._create_annotation_from_item(\n                            item, project_id, user_id, session\n                        )\n                        \n                        session.add(annotation)\n                        session.flush()\n                        \n                        imported_items.append(annotation)\n                        success_count += 1\n                        \n                        # Update progress\n                        if progress_callback:\n                            progress_percentage = (i + 1) / total_items * 100\n                            await progress_callback(\n                                i + 1, total_items, progress_percentage, success_count, failure_count\n                            )\n                    \n                    except Exception as e:\n                        failure_count += 1\n                        errors.append({\n                            \"index\": i,\n                            \"item\": item,\n                            \"error\": str(e)\n                        })\n                        logger.error(f\"Error importing item {i}: {str(e)}\")\n                \n                # Commit all successful imports\n                session.commit()\n                \n                # Calculate execution time\n                execution_time = (datetime.utcnow() - start_time).total_seconds()\n                \n                return ImportResult(\n                    success_count=success_count,\n                    failure_count=failure_count,\n                    errors=errors,\n                    imported_items=imported_items,\n                    validation_warnings=validation_warnings,\n                    metadata={\n                        \"file_format\": file_format,\n                        \"execution_time\": execution_time,\n                        \"total_items\": total_items,\n                        \"project_id\": project_id,\n                        \"user_id\": user_id\n                    }\n                )\n                \n            finally:\n                session.close()\n                \n        except Exception as e:\n            logger.error(f\"Import failed: {str(e)}\")\n            return ImportResult(\n                success_count=0,\n                failure_count=0,\n                errors=[{\"error\": f\"Import failed: {str(e)}\"}],\n                imported_items=[],\n                validation_warnings=[],\n                metadata={\"error\": str(e)}\n            )\n    \n    async def export_annotations_to_format(\n        self,\n        project_id: int,\n        export_format: str,\n        output_path: str,\n        filters: Optional[Dict[str, Any]] = None,\n        include_metadata: bool = True,\n        progress_callback: Optional[callable] = None\n    ) -> ExportResult:\n        \"\"\"\n        Export annotations to various formats.\n        \n        Args:\n            project_id: Project to export from\n            export_format: Target export format\n            output_path: Output file path\n            filters: Query filters for annotations\n            include_metadata: Whether to include metadata\n            progress_callback: Progress callback function\n            \n        Returns:\n            ExportResult with export statistics\n        \"\"\"\n        start_time = datetime.utcnow()\n        session = self.session_factory()\n        \n        try:\n            # Build query\n            query = session.query(Annotation).join(Text).filter(\n                Text.project_id == project_id\n            )\n            \n            # Apply filters\n            if filters:\n                query = self._apply_export_filters(query, filters)\n            \n            # Get annotations with related data\n            annotations = query.all()\n            total_annotations = len(annotations)\n            \n            # Export based on format\n            if export_format.lower() == \"csv\":\n                exported_data = await self._export_to_csv(\n                    annotations, output_path, include_metadata, progress_callback\n                )\n            elif export_format.lower() == \"json\":\n                exported_data = await self._export_to_json(\n                    annotations, output_path, include_metadata, progress_callback\n                )\n            elif export_format.lower() == \"jsonl\":\n                exported_data = await self._export_to_jsonl(\n                    annotations, output_path, include_metadata, progress_callback\n                )\n            elif export_format.lower() == \"xml\":\n                exported_data = await self._export_to_xml(\n                    annotations, output_path, include_metadata, progress_callback\n                )\n            elif export_format.lower() == \"coco\":\n                exported_data = await self._export_to_coco(\n                    annotations, project_id, output_path, progress_callback\n                )\n            elif export_format.lower() == \"yolo\":\n                exported_data = await self._export_to_yolo(\n                    annotations, project_id, output_path, progress_callback\n                )\n            elif export_format.lower() == \"conll\":\n                exported_data = await self._export_to_conll(\n                    annotations, output_path, progress_callback\n                )\n            else:\n                raise ValueError(f\"Unsupported export format: {export_format}\")\n            \n            # Get file size\n            file_size = Path(output_path).stat().st_size\n            \n            # Calculate execution time\n            execution_time = (datetime.utcnow() - start_time).total_seconds()\n            \n            return ExportResult(\n                exported_count=total_annotations,\n                export_file_path=output_path,\n                file_size_bytes=file_size,\n                format=export_format,\n                metadata={\n                    \"execution_time\": execution_time,\n                    \"project_id\": project_id,\n                    \"include_metadata\": include_metadata,\n                    \"filters_applied\": filters is not None\n                }\n            )\n            \n        finally:\n            session.close()\n    \n    def _parse_csv_content(\n        self, \n        content: bytes, \n        mapping_config: Optional[Dict[str, str]] = None\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Parse CSV content into annotation data.\"\"\"\n        text_content = content.decode('utf-8')\n        reader = csv.DictReader(StringIO(text_content))\n        \n        data = []\n        for row in reader:\n            item = {}\n            \n            # Apply field mapping if provided\n            if mapping_config:\n                for csv_field, annotation_field in mapping_config.items():\n                    if csv_field in row:\n                        item[annotation_field] = self._convert_field_value(\n                            row[csv_field], annotation_field\n                        )\n            else:\n                # Use default mapping\n                item = {\n                    \"start_char\": int(row.get(\"start_char\", 0)),\n                    \"end_char\": int(row.get(\"end_char\", 0)),\n                    \"selected_text\": row.get(\"selected_text\", \"\"),\n                    \"text_id\": int(row.get(\"text_id\", 0)),\n                    \"label_id\": int(row.get(\"label_id\", 0)),\n                    \"notes\": row.get(\"notes\", \"\"),\n                    \"confidence_score\": float(row.get(\"confidence_score\", 1.0))\n                }\n            \n            data.append(item)\n        \n        return data\n    \n    def _parse_json_content(\n        self, \n        content: bytes, \n        mapping_config: Optional[Dict[str, str]] = None\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Parse JSON content into annotation data.\"\"\"\n        text_content = content.decode('utf-8')\n        json_data = json.loads(text_content)\n        \n        if isinstance(json_data, list):\n            return json_data\n        elif \"annotations\" in json_data:\n            return json_data[\"annotations\"]\n        else:\n            return [json_data]\n    \n    def _parse_jsonl_content(\n        self, \n        content: bytes, \n        mapping_config: Optional[Dict[str, str]] = None\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Parse JSONL (JSON Lines) content into annotation data.\"\"\"\n        text_content = content.decode('utf-8')\n        lines = text_content.strip().split('\\n')\n        \n        data = []\n        for line in lines:\n            if line.strip():\n                item = json.loads(line)\n                data.append(item)\n        \n        return data\n    \n    def _parse_xml_content(\n        self, \n        content: bytes, \n        mapping_config: Optional[Dict[str, str]] = None\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Parse XML content into annotation data.\"\"\"\n        text_content = content.decode('utf-8')\n        root = ET.fromstring(text_content)\n        \n        data = []\n        for annotation_elem in root.findall('.//annotation'):\n            item = {}\n            for child in annotation_elem:\n                if child.tag in [\"start_char\", \"end_char\", \"text_id\", \"label_id\"]:\n                    item[child.tag] = int(child.text)\n                elif child.tag == \"confidence_score\":\n                    item[child.tag] = float(child.text)\n                else:\n                    item[child.tag] = child.text\n            \n            data.append(item)\n        \n        return data\n    \n    def _parse_coco_content(\n        self, \n        content: bytes, \n        project_id: int\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Parse COCO format content into annotation data.\"\"\"\n        text_content = content.decode('utf-8')\n        coco_data = json.loads(text_content)\n        \n        # Convert COCO format to internal format\n        # This would need to be implemented based on COCO structure\n        # For now, return empty list\n        return []\n    \n    def _parse_yolo_content(\n        self, \n        content: bytes, \n        project_id: int\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Parse YOLO format content into annotation data.\"\"\"\n        # YOLO format is typically text-based with space-separated values\n        # This would need to be implemented based on YOLO structure\n        return []\n    \n    def _validate_import_item(\n        self,\n        item: Dict[str, Any],\n        project_id: int,\n        session: Session,\n        validation_config: Optional[Dict[str, Any]] = None\n    ) -> Dict[str, Any]:\n        \"\"\"Validate an import item.\"\"\"\n        errors = []\n        warnings = []\n        \n        # Check required fields\n        required_fields = [\"start_char\", \"end_char\", \"selected_text\", \"text_id\", \"label_id\"]\n        for field in required_fields:\n            if field not in item or item[field] is None:\n                errors.append(f\"Missing required field: {field}\")\n        \n        # Validate span\n        if \"start_char\" in item and \"end_char\" in item:\n            if item[\"start_char\"] >= item[\"end_char\"]:\n                errors.append(\"Invalid span: start_char must be less than end_char\")\n        \n        # Validate foreign keys\n        if \"text_id\" in item:\n            text_exists = session.query(Text).filter(\n                Text.id == item[\"text_id\"],\n                Text.project_id == project_id\n            ).first() is not None\n            \n            if not text_exists:\n                errors.append(f\"Text ID {item['text_id']} not found in project\")\n        \n        if \"label_id\" in item:\n            label_exists = session.query(Label).filter(\n                Label.id == item[\"label_id\"],\n                Label.project_id == project_id\n            ).first() is not None\n            \n            if not label_exists:\n                errors.append(f\"Label ID {item['label_id']} not found in project\")\n        \n        return {\n            \"valid\": len(errors) == 0,\n            \"errors\": errors,\n            \"warnings\": warnings\n        }\n    \n    def _create_annotation_from_item(\n        self,\n        item: Dict[str, Any],\n        project_id: int,\n        user_id: int,\n        session: Session\n    ) -> Annotation:\n        \"\"\"Create an Annotation object from import item.\"\"\"\n        return Annotation(\n            start_char=item[\"start_char\"],\n            end_char=item[\"end_char\"],\n            selected_text=item[\"selected_text\"],\n            notes=item.get(\"notes\"),\n            confidence_score=item.get(\"confidence_score\", 1.0),\n            metadata=item.get(\"metadata\", {}),\n            context_before=item.get(\"context_before\"),\n            context_after=item.get(\"context_after\"),\n            text_id=item[\"text_id\"],\n            annotator_id=user_id,\n            label_id=item[\"label_id\"]\n        )\n    \n    def _convert_field_value(self, value: str, field_name: str) -> Any:\n        \"\"\"Convert field value to appropriate type.\"\"\"\n        if field_name in [\"start_char\", \"end_char\", \"text_id\", \"label_id\"]:\n            return int(value)\n        elif field_name == \"confidence_score\":\n            return float(value)\n        else:\n            return value\n    \n    def _apply_export_filters(\n        self, \n        query, \n        filters: Dict[str, Any]\n    ):\n        \"\"\"Apply filters to export query.\"\"\"\n        if \"status\" in filters:\n            query = query.filter(Annotation.is_validated == filters[\"status\"])\n        if \"label_id\" in filters:\n            query = query.filter(Annotation.label_id == filters[\"label_id\"])\n        if \"user_id\" in filters:\n            query = query.filter(Annotation.annotator_id == filters[\"user_id\"])\n        if \"created_after\" in filters:\n            query = query.filter(Annotation.created_at >= filters[\"created_after\"])\n        if \"created_before\" in filters:\n            query = query.filter(Annotation.created_at <= filters[\"created_before\"])\n        \n        return query\n    \n    async def _export_to_csv(\n        self,\n        annotations: List[Annotation],\n        output_path: str,\n        include_metadata: bool,\n        progress_callback: Optional[callable] = None\n    ) -> None:\n        \"\"\"Export annotations to CSV format.\"\"\"\n        with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:\n            fieldnames = [\n                'id', 'start_char', 'end_char', 'selected_text', 'notes',\n                'confidence_score', 'context_before', 'context_after',\n                'is_validated', 'text_id', 'annotator_id', 'label_id',\n                'label_name', 'annotator_username', 'created_at', 'updated_at'\n            ]\n            \n            if include_metadata:\n                fieldnames.append('metadata')\n            \n            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n            writer.writeheader()\n            \n            for i, annotation in enumerate(annotations):\n                row = {\n                    'id': annotation.id,\n                    'start_char': annotation.start_char,\n                    'end_char': annotation.end_char,\n                    'selected_text': annotation.selected_text,\n                    'notes': annotation.notes,\n                    'confidence_score': annotation.confidence_score,\n                    'context_before': annotation.context_before,\n                    'context_after': annotation.context_after,\n                    'is_validated': annotation.is_validated,\n                    'text_id': annotation.text_id,\n                    'annotator_id': annotation.annotator_id,\n                    'label_id': annotation.label_id,\n                    'label_name': annotation.label.name if annotation.label else '',\n                    'annotator_username': annotation.annotator.username if annotation.annotator else '',\n                    'created_at': annotation.created_at.isoformat() if annotation.created_at else '',\n                    'updated_at': annotation.updated_at.isoformat() if annotation.updated_at else ''\n                }\n                \n                if include_metadata:\n                    row['metadata'] = json.dumps(annotation.metadata) if annotation.metadata else '{}'\n                \n                writer.writerow(row)\n                \n                # Update progress\n                if progress_callback:\n                    progress_percentage = (i + 1) / len(annotations) * 100\n                    await progress_callback(i + 1, len(annotations), progress_percentage)\n    \n    async def _export_to_json(\n        self,\n        annotations: List[Annotation],\n        output_path: str,\n        include_metadata: bool,\n        progress_callback: Optional[callable] = None\n    ) -> None:\n        \"\"\"Export annotations to JSON format.\"\"\"\n        export_data = {\n            \"annotations\": [],\n            \"export_info\": {\n                \"exported_at\": datetime.utcnow().isoformat(),\n                \"total_annotations\": len(annotations),\n                \"include_metadata\": include_metadata\n            }\n        }\n        \n        for i, annotation in enumerate(annotations):\n            annotation_data = annotation.to_dict()\n            \n            if not include_metadata and 'metadata' in annotation_data:\n                del annotation_data['metadata']\n            \n            export_data[\"annotations\"].append(annotation_data)\n            \n            # Update progress\n            if progress_callback:\n                progress_percentage = (i + 1) / len(annotations) * 100\n                await progress_callback(i + 1, len(annotations), progress_percentage)\n        \n        with open(output_path, 'w', encoding='utf-8') as jsonfile:\n            json.dump(export_data, jsonfile, indent=2, ensure_ascii=False)\n    \n    async def _export_to_jsonl(\n        self,\n        annotations: List[Annotation],\n        output_path: str,\n        include_metadata: bool,\n        progress_callback: Optional[callable] = None\n    ) -> None:\n        \"\"\"Export annotations to JSONL format.\"\"\"\n        with open(output_path, 'w', encoding='utf-8') as jsonlfile:\n            for i, annotation in enumerate(annotations):\n                annotation_data = annotation.to_dict()\n                \n                if not include_metadata and 'metadata' in annotation_data:\n                    del annotation_data['metadata']\n                \n                jsonlfile.write(json.dumps(annotation_data, ensure_ascii=False) + '\\n')\n                \n                # Update progress\n                if progress_callback:\n                    progress_percentage = (i + 1) / len(annotations) * 100\n                    await progress_callback(i + 1, len(annotations), progress_percentage)\n    \n    async def _export_to_xml(\n        self,\n        annotations: List[Annotation],\n        output_path: str,\n        include_metadata: bool,\n        progress_callback: Optional[callable] = None\n    ) -> None:\n        \"\"\"Export annotations to XML format.\"\"\"\n        root = ET.Element(\"annotations\")\n        \n        for i, annotation in enumerate(annotations):\n            annotation_elem = ET.SubElement(root, \"annotation\")\n            \n            # Add annotation fields\n            for field, value in annotation.to_dict().items():\n                if not include_metadata and field == 'metadata':\n                    continue\n                \n                field_elem = ET.SubElement(annotation_elem, field)\n                field_elem.text = str(value) if value is not None else ''\n            \n            # Update progress\n            if progress_callback:\n                progress_percentage = (i + 1) / len(annotations) * 100\n                await progress_callback(i + 1, len(annotations), progress_percentage)\n        \n        # Write to file\n        tree = ET.ElementTree(root)\n        tree.write(output_path, encoding='utf-8', xml_declaration=True)\n    \n    async def _export_to_coco(\n        self,\n        annotations: List[Annotation],\n        project_id: int,\n        output_path: str,\n        progress_callback: Optional[callable] = None\n    ) -> None:\n        \"\"\"Export annotations to COCO format.\"\"\"\n        # This would implement COCO format export\n        # For now, create basic structure\n        coco_data = {\n            \"info\": {\n                \"description\": \"Exported from annotation system\",\n                \"version\": \"1.0\",\n                \"year\": datetime.utcnow().year,\n                \"date_created\": datetime.utcnow().isoformat()\n            },\n            \"images\": [],\n            \"annotations\": [],\n            \"categories\": []\n        }\n        \n        with open(output_path, 'w', encoding='utf-8') as cocofile:\n            json.dump(coco_data, cocofile, indent=2)\n    \n    async def _export_to_yolo(\n        self,\n        annotations: List[Annotation],\n        project_id: int,\n        output_path: str,\n        progress_callback: Optional[callable] = None\n    ) -> None:\n        \"\"\"Export annotations to YOLO format.\"\"\"\n        # YOLO format implementation would go here\n        with open(output_path, 'w', encoding='utf-8') as yolofile:\n            for i, annotation in enumerate(annotations):\n                # Write YOLO format line\n                # This is a placeholder\n                yolofile.write(f\"0 0.5 0.5 0.1 0.1\\n\")\n                \n                if progress_callback:\n                    progress_percentage = (i + 1) / len(annotations) * 100\n                    await progress_callback(i + 1, len(annotations), progress_percentage)\n    \n    async def _export_to_conll(\n        self,\n        annotations: List[Annotation],\n        output_path: str,\n        progress_callback: Optional[callable] = None\n    ) -> None:\n        \"\"\"Export annotations to CoNLL format.\"\"\"\n        with open(output_path, 'w', encoding='utf-8') as conllfile:\n            for i, annotation in enumerate(annotations):\n                # Write CoNLL format\n                # This would need proper token-level annotation handling\n                words = annotation.selected_text.split()\n                for j, word in enumerate(words):\n                    if j == 0:\n                        tag = f\"B-{annotation.label.name}\" if annotation.label else \"O\"\n                    else:\n                        tag = f\"I-{annotation.label.name}\" if annotation.label else \"O\"\n                    \n                    conllfile.write(f\"{word}\\t{tag}\\n\")\n                \n                conllfile.write(\"\\n\")  # Sentence separator\n                \n                if progress_callback:\n                    progress_percentage = (i + 1) / len(annotations) * 100\n                    await progress_callback(i + 1, len(annotations), progress_percentage)\n    \n    def get_supported_formats(self) -> Dict[str, List[str]]:\n        \"\"\"Get list of supported import and export formats.\"\"\"\n        return {\n            \"import\": self.supported_import_formats,\n            \"export\": self.supported_export_formats\n        }\n    \n    def validate_format(self, file_format: str, operation: str) -> bool:\n        \"\"\"Validate if a format is supported for import or export.\"\"\"\n        if operation == \"import\":\n            return file_format.lower() in self.supported_import_formats\n        elif operation == \"export\":\n            return file_format.lower() in self.supported_export_formats\n        else:\n            return False